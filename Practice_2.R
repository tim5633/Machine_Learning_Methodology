library(simstudy) #for simulating the dataset
library(caret) #for creating the svm model
library(e1071) # for plotting 

################################################################################
##### simulation the dataset ###################################################
################################################################################

#For class 1, the dataset is generated by normal distributtion from (0,0) with variance of 0.03.
#Noted that some of the class1 data would be at the same range to class2 to create some noise;
#For class 2, the dataset is randomly generated within a circle of radius = 0.4; 
#For class 3, the dataset is randomly generated within a circle of radius = 0.6. 
#Finally with using rbind to create a dataframe of three classes, 
#and turned label vector into factor to plot and make model.

# class 1 simulation: central area: usinf the simstudy package
set.seed(6666)
d <- defData(varname = "x1", formula = 0,  
             dist = "normal", variance = 0.03) 
dc <- defCondition(condition = "x1 == x1", formula = 0,
                   dist = "normal", variance = 0.03) 

df_1 <- genData(50, d)
df_1 <- addCondition(dc, df_1, newvar = "x2")
df_1$class <- 1
df_1$id <- NULL
df_1 <- as.data.frame(df_1)

# class 2 simulation: second layer with making a circle and randomly disatributed
set.seed(66)
radius = 0.4
theta = runif(50, min = 0, max = 2*pi)
x = radius * cos(theta)
y = radius * sin(theta)

df_2 <- NULL
df_2$x1 <- x
df_2$x2 <- y
df_2$class <- 2
df_2 <- as.data.frame(df_2)

# class 3 simulation: third layer with bigger circle 
set.seed(666)
radius_2 = 0.6
thet_2 = runif(50, min = 0, max = 2*pi)
x_2 = radius_2 * cos(thet_2)
y_2 = radius_2 * sin(thet_2)

df_3 <- NULL
df_3$x1 <- x_2
df_3$x2 <- y_2
df_3$class <- 3
df_3 <- as.data.frame(df_3)

# binding three dataset above together
df <- rbind(df_1, df_2, df_3)

# plotting scatter out
df$class <- factor(df$class)
ggplot(df) + geom_point(aes(x1, x2, col=class))+ ggtitle("Plot of three-class dataset")

################################################################################
##### Split to training set 50% and test set 50% ###############################
################################################################################
set.seed(66) 
train_index <- createDataPartition(df$class,p=0.5,list=FALSE) 
train <- df[train_index,]
test <- df[-train_index,]

################################################################################
##### SVM - linear kernel ######################################################
################################################################################
# Setup for trainControl
fitControl=trainControl(
  method = "repeatedcv",
  number = 5, # 5-fold cross-validation
  repeats = 1)

# Fit the model on the training set
set.seed(6666)
svm_Linear=train(class ~.,
                 data = train, 
                 method = "svmLinear",
                 trControl=fitControl,
                 preProcess = c("center", "scale"),
                 tuneGrid = expand.grid(C = c(0.2,0.4,0.6,0.8,1,1.2,1.4,1.6,1.8,2))
                 # The default setting is holding a constant of cost = 1
                 # with tuneGrid might find better model
                 )
                 
svm_Linear  
# The final value used for the model was C = 0.4 with Accuracy 0.5600000
plot(svm_Linear) # all of the accuracy of costs are all below 0.60

# Compute model accuracy rate
pred <- predict(svm_Linear, test[,-3])
mean(pred == test[,3]) #[1] 0.4133333

# Overall Statistics
Linear_matrix = confusionMatrix(pred,test[,3])
Linear_matrix # P-Value [Acc > NIR] : 0.09044 

# using the e1071 package for plotting: with the same model of caret of fixed c = 0.2 
svm_Linear_e1071 <- svm(class ~ ., data = train, kernel = 'linear', cost =0.2 )
plot(svm_Linear_e1071, data = test) # shows that its classification is quite bad

################################################################################
##### SVM - polynomial kernel ##################################################
################################################################################
# Setup for cross validation
fitControl=trainControl(
  method = "repeatedcv",
  number = 5, # 5-fold cross-validation
  repeats = 1)

# Fit the model on the training set
set.seed(666)
svm_Poly <- train(class ~.,
                  data = train,
                  method = "svmPoly",
                  trControl = fitControl,
                  preProcess = c("center","scale"),
                  tuneLength = 5
                  )

# Print the best tuning parameter sigma and C that
svm_Poly 
# The final values used for the model were degree = 2, scale = 1 and C = 4
# Accuracy 0.9066667

plot(svm_Poly)

# Compute model accuracy rate
pred <- predict(svm_Poly, test[,-3])
mean(pred == test[,3]) #Accuracy 0.9466667

# Overall Statistics
Poly_matrix = confusionMatrix(pred,test[,3])
Poly_matrix # P-Value [Acc > NIR] : < 2.2e-16

# using the e1071 package for plotting
svm_Poly_e1071 <- svm(class ~ .,
                      data = train,
                      kernel = 'polynomial',
                      cost =4,
                      degree = 2,
                      double = 1 ## In any(scale) : coercing argument of type 'double' to logical
                      )
plot(svm_Poly_e1071, data = test)

################################################################################
##### SVM - RBF kernel #########################################################
################################################################################
# Setup for cross validation
fitControl=trainControl(
  method = "repeatedcv", 
  number = 5, # 5-fold cross-validation
  repeats = 1)

# Fit the model on the training set
set.seed(666)
svm_Radial=train(class ~.,
                 data = train,
                 method = "svmRadial",
                 trControl=fitControl,
                 preProcess = c("center", "scale"),
                 tuneLength = 5
                 )

svm_Radial #sigma = 0.5250217 and C = 2. #Accuracy 0.8800000

plot(svm_Radial)

# Compute model accuracy rate
pred <- predict(svm_Radial, test[,-3])
mean(pred == test[,3]) # Accuracy 0.9333333

# Overall Statistics
RBF_matrix = confusionMatrix(pred,test[,3])
RBF_matrix # P-Value [Acc > NIR] : < 2.2e-16   

# using the e1071 package for plotting
svm_RBF_e1071 <- svm(class ~ .,
                     data = train,
                     kernel = 'radial',
                     C =1,
                     gamma =0.5250217  )
plot(svm_RBF_e1071, data = test)

